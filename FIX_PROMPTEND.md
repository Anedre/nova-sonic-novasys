# Fix: Esperar promptEnd y Formato JSON Correcto

## Problema Identificado

```
Error: "Unable to parse input chunk. Please check input format contains correct format."
```

**Causa Ra√≠z**: Dos problemas combinados:
1. **Formato JSON incorrecto**: Us√°bamos `json.dumps(payload, ensure_ascii=True)` que el modelo rechazaba
2. **Eventos enviados demasiado r√°pido**: Sin delays entre eventos de inicializaci√≥n
3. **Contexto gigante en un solo chunk**: Era mejor enviarlo fragmentado por fuente
4. **Timing incorrecto**: Intent√°bamos enviar audio antes de recibir confirmaci√≥n del modelo

## Flujo Incorrecto (Antes)

```
1. sessionStart + promptStart + context sources (SIN DELAYS)
2. contentStart (audio) ‚Üê ‚ùå DEMASIADO PRONTO
3. Modelo rechaza: "Unable to parse input chunk"
```

## Flujo Correcto (Ahora)

Seg√∫n el patr√≥n oficial de AWS Nova Sonic:

```
1. Cliente env√≠a:
   ‚îú‚îÄ sessionStart
   ‚îú‚îÄ [delay 0.1s]
   ‚îú‚îÄ promptStart  
   ‚îú‚îÄ [delay 0.1s]
   ‚îú‚îÄ context sources (contentStart ‚Üí textInput ‚Üí contentEnd con delays 0.05s)
   ‚îî‚îÄ [delay 0.1s]

2. ‚è≥ ESPERAR ‚Üí Modelo responde: promptEnd

3. ‚úÖ SOLO AHORA Cliente env√≠a:
   ‚îî‚îÄ contentStart (audio)

4. Streaming continuo de audio chunks
```

## Cambios Implementados

### 1. `nova_sonic_es_sd.py`

**Agregado flag de sincronizaci√≥n:**

```python
# En __init__
self._prompt_ready = asyncio.Event()  # Flag para esperar promptEnd
```

**Modificado `send_audio_content_start_event()`:**

```python
async def send_audio_content_start_event(self) -> None:
    # Esperar confirmaci√≥n del modelo
    self._debug("‚è≥ Esperando confirmaci√≥n del modelo (promptEnd)...")
    await asyncio.wait_for(self._prompt_ready.wait(), timeout=10)
    self._debug("‚úÖ Modelo listo, enviando contentStart para audio")
    # ... resto del c√≥digo
```

**Agregado manejo de evento `promptEnd`:**

```python
async def _handle_model_payload(self, payload: Dict[str, Any]) -> None:
    # ... c√≥digo existente ...
    
    if "promptEnd" in event:
        self._debug("‚úÖ Recibido promptEnd - modelo listo para audio")
        self._prompt_ready.set()  # Desbloquea send_audio_content_start_event
```

**Removido `ensure_ascii=True` de `_send_event()`:**

```python
# Antes:
data = json.dumps(payload, ensure_ascii=True)  # ‚ùå Causaba errores

# Ahora:
data = json.dumps(payload)  # ‚úÖ Formato compatible con Nova Sonic
```

**Agregados delays en `initialize_stream()`:**

```python
async def initialize_stream(self) -> "BedrockStreamManager":
    # ... c√≥digo de inicializaci√≥n ...
    
    await self._send_event(self._build_session_start_event())
    await asyncio.sleep(0.1)  # ‚úÖ Delay como en ejemplo oficial
    await self._send_event(self._build_prompt_start_event())
    await asyncio.sleep(0.1)
    await self._send_context_sources()
    await asyncio.sleep(0.1)  # ‚úÖ Esperar que el modelo procese
    
    self._reader_task = asyncio.create_task(self._read_loop())
    return self
```

**Agregados delays en `_send_text_block()` y fragmentaci√≥n de contexto:**

```python
await self._send_event(start)
await asyncio.sleep(0.05)  # ‚úÖ Delay entre eventos
await self._send_event(body)
await asyncio.sleep(0.05)
await self._send_event(end)

**`_send_context_sources()` ahora env√≠a cada bloque por separado:**

```python
for src in self.context_sources:
    text = src.render().strip()
    self._debug(f"üìö Enviando contexto ({role}) len={len(text)}")
    await self._send_text_block(text, role=role)
    await asyncio.sleep(0.05)
```
```

### 2. `nova_sonic_web_adapter_v3.py`

**Simplificado bootstrap:**

```python
# Antes:
await self.manager.initialize_stream()
self._log("‚úÖ Stream inicializado")
await self.manager.send_audio_content_start_event()
await asyncio.sleep(0.1)  # Delay innecesario

# Ahora:
await self.manager.initialize_stream()
self._log("‚úÖ Stream inicializado, esperando confirmaci√≥n del modelo...")
await self.manager.send_audio_content_start_event()  # Espera internamente
self._log("üé¨ Sesi√≥n lista")
```

## Validaci√≥n

### Logs Esperados (Correctos):

```
[HH:MM:SS] üì° Solicitando stream Nova Sonic...
[HH:MM:SS] ‚Üí Evento enviado (['sessionStart']): {...}
[HH:MM:SS] ‚Üí Evento enviado (['promptStart']): {...}
[HH:MM:SS] ‚Üí Evento enviado (['contentStart']): {"role": "SYSTEM"...}
[HH:MM:SS] ‚Üí Evento enviado (['textInput']): {...}
[HH:MM:SS] ‚Üí Evento enviado (['contentEnd']): {...}
[HH:MM:SS] ‚úÖ Stream inicializado, esperando confirmaci√≥n del modelo...
[HH:MM:SS] ‚è≥ Esperando confirmaci√≥n del modelo (promptEnd)...
[HH:MM:SS] ‚úÖ Recibido promptEnd - modelo listo para audio
[HH:MM:SS] ‚úÖ Modelo listo, enviando contentStart para audio
[HH:MM:SS] ‚Üí Evento enviado (['contentStart']): {"type": "AUDIO"...}
[HH:MM:SS] üé¨ Sesi√≥n lista: enviando audio continuo
[HH:MM:SS] üì§ Audio enviado: X KB
```

### ‚ùå Si el modelo no responde promptEnd:

```
[HH:MM:SS] ‚è≥ Esperando confirmaci√≥n del modelo (promptEnd)...
[HH:MM:SS] ‚ùå RuntimeError: Timeout esperando promptEnd del modelo
```

Esto indicar√≠a un problema con las credenciales AWS o la configuraci√≥n del modelo.

## Referencias

- **AWS Official Sample**: `amazon-nova-samples/speech-to-speech/sample-codes/console-python/nova_sonic_tool_use.py`
- **Patr√≥n documentado**: Siempre esperar `promptEnd` antes de enviar contenido interactivo

## Testing

1. Iniciar servidor: `python app.py`
2. Abrir navegador: http://localhost:5000
3. Iniciar llamada
4. Verificar en logs:
   - ‚úÖ "Esperando confirmaci√≥n del modelo"
   - ‚úÖ "Recibido promptEnd"
   - ‚úÖ "Modelo listo, enviando contentStart"
   - ‚ùå NO debe aparecer "Unable to parse input chunk"

---

**Fecha**: 31 Oct 2025  
**Versi√≥n**: V3.1 (Fix promptEnd)
